---
title: Description - Visual Creativity & Image Generation
layout: default
nav_order: 5
---

# Module: Description - Visual Creativity & Image Generation

## Overview

**The Core Skill: Translating Intent Into Specific Language**

This module is fundamentally about **Description** - the second D in the 4D Framework. Whether you're generating an image or asking AI to teach you something complex, vague language produces vague results. Description forces you to think clearly about what you actually want and translate that intent into precise, actionable language.

You'll practice Description in two contexts:
- **Visual prompts** (image generation): Where every detail matters - subject, style, lighting, composition
- **Complex text prompts** (learning new skills): Where structure matters - role, context, requirements, format

**What You'll Do:**
- Complete the Anthropic AI Fluency Description sections and use NotebookLM to help you understand them
- Learn the structure of effective image prompts (Subject + Style + Composition + Lighting + Details)
- Create a baseline image and iterate by changing ONE variable at a time
- Generate 2 polished creative images using everything you've learned
- Master the 6-component framework for complex prompts (role, context, task, structure, constraints, format)
- Use AI to learn a complex card game through structured prompting
- Document all experiments in NotebookLM and use it to analyze your progress

**Why This Matters:**
Description is your multiplier skill. The better you can describe what you want, the better results you'll get from ANY AI tool. Image generation is the perfect training ground because you get immediate visual feedback on whether your description was specific enough. Then you'll apply those same principles to complex text tasks - and discover that clear description works everywhere.

---

## Step 0: Installing the tools

You already have most tools from Foundation Part 1, but you'll need to set up image generation.

### Image Generation Tool Setup

**Choose at least ONE free option:**

**Option A: ChatGPT with DALL-E (FREE)**
- Already installed from Foundation Part 1
- Free tier: 2-3 images per day
- Access: ChatGPT iOS app
- Steps:
  1. Open ChatGPT app
  2. Start a new chat
  3. Type: "Create an image: a friendly corgi, simple illustration"
  4. Verify it generates an image and you can save it

**Option B: Leonardo.Ai (FREE)**
- Free tier: Daily credits for image generation
- App: [Leonardo.Ai on App Store](https://leonardo.ai) or use mobile browser
- Steps:
  1. Visit leonardo.ai or install iOS app
  2. Create account (sign in with Google/email)
  3. Choose "Image Generation"
  4. Test with: "a friendly corgi, simple illustration"
  5. Verify you can download images

**Option C : MidJourney (PAID - $10/mo)**
- Highest artistic quality, accessed via Discord
- App: Discord on iOS + MidJourney subscription
- Best for: Professional-quality creative work
- Only choose this if you want to invest in premium results

**Which should you choose?**
- Start with ChatGPT if you're already comfortable with it
- Try Leonardo.Ai if you want more daily generations
- Add MidJourney later if you need highest quality

---

## Course Orientation: Understanding Description Through AI

### Get the Full Picture First

Before generating images, ground yourself in Description principles from the Anthropic AI Fluency course. Then you'll use NotebookLM to help you understand how to use your image generation tool.

**Step 0: Add Your Course Materials**
1. **Download and add Foundation modules** to your NotebookLM notebook:
   - Add this current document. You can copy-paste the content or upload the files directly by downloading them from  https://github.com/howzat/ai-research-onboarding/tree/main/docs

**Step 1: Capture the AI Fluency Description Sections**

1. Go to [Anthropic AI Fluency Course](https://anthropic.skilljar.com/ai-fluency-framework-foundations)
2. Sign in (or create Skilljar account if needed)
3. Watch and capture these 4 sections (in order):
   - **Description**
   - **A closer look at Description**
   - **Deep Dive 2: Effective prompting techniques**
   - **Effective prompting techniques**

4. For each section, copy the video transcript or lesson text

5. Open NotebookLM and add each as a SEPARATE source:
   - "AI Fluency - Description"
   - "AI Fluency - A closer look at Description"
   - "AI Fluency - Deep Dive 2: Effective prompting techniques"
   - "AI Fluency - Effective prompting techniques"

**Step 2: Add Your Image Tool Documentation**

This is key - you'll use NotebookLM to help you learn your chosen tool! The task here is to find some information on how to use the tool and give it to Notebook LM in order to help you understand how to use it. 

You should use Chat GPT or Claude to consume the docs and tell it generate a manual to to give to Notebook LM (be careful with this approach - AIs make things up!). Use a prompt like
 
>read them THOROUGHLY and give you a comprehensive and detailed instruction manual 

Or you can try a META prompt such as

>	I want to create a manual for using midjourney. Using this https://docs.midjourney.com/hc/en-us/articles/33329261836941-Getting-Started-Guide I need an AI to read them THOROUGHLY and give you a comprehensive and detailed instruction manual . Give me a prompt that will provide me with a high quality output, the output of the prompt should result in a markdown file that I can download, or cut and paste into Notebook LM

**Try these resources**

- **If using ChatGPT/DALL-E**: Go to [OpenAI DALL-E Guide](https://platform.openai.com/docs/guides/images), copy the content, add to NotebookLM as source: "DALL-E Guide"
- **If using Leonardo.Ai**: Browse their [Help Center](https://intercom.help/leonardo-ai/en/collections/4884882-help-guides), find getting started/prompting guides, copy relevant sections, add as source: "Leonardo.Ai Guide"
- **If using MidJourney**: Go to [MidJourney Prompting Guide](https://docs.midjourney.com/hc/en-us/articles/33329261836941-Getting-Started-Guide), copy the content, add as source: "MidJourney Prompting Guide"

**Step 3: Ask NotebookLM to Help You**

Now you have both the Description theory AND your tool documentation in NotebookLM. Use it!

Ask NotebookLM:
- "How do the Description principles from the AI Fluency sections apply to image generation?"
- "Based on the [your tool] guide, what are 3 key elements of effective image prompts?"
- "What does the Description lesson say about being specific vs vague?"

Click the citations to see where each answer comes from. This is NotebookLM showing you it's not making things up - it's pulling from YOUR sources.

**Step 4: Generate Your Study Guide**

- Click "Study Guide" in NotebookLM
- Answer at least 3 quiz questions about Description principles
- Save any concepts you didn't know

**Why this works:**
By adding both theory (Description lessons) and practical docs (tool guides) to NotebookLM, you're creating your personal AI learning assistant. It can connect the Description principles to your specific tool and help you when you get stuck.

---

## Step 1: Understanding Image Prompt Structure

**Image prompts have a formula** (just like written communication has grammar):

```
[SUBJECT] + [STYLE] + [COMPOSITION] + [LIGHTING] + [DETAILS/MEDIUM]
```

**Examples:**

**Minimal prompt (vague):**
```
A dog at a cafe
```
Result: Generic. AI chooses everything. You have no control.

**Structured prompt (specific):**
```
Golden retriever wearing sunglasses, sitting at outdoor cafe table, Paris street background, watercolor illustration style, warm golden hour lighting, soft pastel colors, loose brushstrokes
```
Result: Controlled. Matches your vision. AI follows YOUR description.

**Key Principle (from Description):**
The more specific and structured your description, the more control you have over the output. Vague descriptions give AI too much freedom to guess. Structured descriptions guide AI toward your intent.

**Two types of structured prompts in this module:**

This module teaches you TWO frameworks for Description:

1. **Image prompts** (this step): Subject + Style + Composition + Lighting + Details
   - Use when: Generating images, visual content
   - Why it matters: Visual specificity requires describing what you see

2. **Complex text prompts** (Step 4): 6-component framework (Role, Context, Task, Structure, Constraints, Format)
   - Use when: Learning new skills, creating plans, analyzing information
   - Why it matters: Complex tasks require describing how you want the AI to think and respond

Both frameworks share the same core principle: **Structure transforms vague requests into specific instructions.** Images need visual structure (what it looks like), complex tasks need process structure (how to approach it).

Let's start with images, then we'll apply the same thinking to text later.

---

**Create a reference source for yourself:**

1. In a note or doc, write:
```markdown
# Image Prompt Structure Formula

SUBJECT: What is the main focus? (person, object, scene)
STYLE: Artistic style (watercolor, digital art, photography, 3D render, illustration)
COMPOSITION: Framing (portrait, landscape, close-up, wide shot, bird's eye view)
LIGHTING: Mood through light (golden hour, overcast, dramatic shadows, bright, soft)
DETAILS: 2-3 specific elements that matter (colors, textures, mood, specific objects)

Example:
Travel researcher's mobile workspace (SUBJECT), iPhone displaying NotebookLM interface, voice recording waveforms visible, European cafe table setting (DETAILS), warm afternoon sunlight (LIGHTING), shallow depth of field (COMPOSITION), illustrated style with soft colors and clean lines (STYLE), peaceful and focused mood (DETAILS)
```

2. Add this to NotebookLM as a new source: "Image Prompt Structure Formula"

3. Ask NotebookLM:
   - "Based on my tool guide and the prompt structure formula, how should I structure my first image prompt?"

---

## Step 2: Your First Image Experiments - Baseline + Iterations

**The Exercise:**

Create one baseline image, then iterate by changing **ONLY ONE variable at a time**. This teaches you what each element actually controls.

**Part A: Create Your Baseline Prompt**

Choose a subject meaningful to your travel/learning journey:
- A place you've visited or want to visit
- Your mobile learning setup
- A visual metaphor for your AI learning journey
- Something personal and creative

**Write your baseline prompt using the formula:**

Example (course context):
```
A travel researcher's mobile workspace, iPhone displaying NotebookLM interface, voice recording waveforms visible, European cafe table setting, warm afternoon sunlight, shallow depth of field, illustrated style with soft colors and clean lines, peaceful and focused mood
```

1. Write your complete baseline prompt
2. Generate the image in your chosen tool
3. Save it with filename: "baseline.png" or similar

**Part B: Single-Variable Iterations**

Create 3 variations, changing **ONLY ONE element** each time:

**Iteration 1 - Style Change:**
- Keep: Same subject, composition, lighting, details
- Change: Artistic style only
- Example: illustrated style → realistic photography → watercolor
- Generate and save as "iteration-1-style.png"

**Iteration 2 - Lighting Change:**
- Keep: Same subject, style, composition, details
- Change: Lighting only
- Example: warm afternoon sunlight → overcast grey → dramatic side lighting
- Generate and save as "iteration-2-lighting.png"

**Iteration 3 - Composition Change:**
- Keep: Same subject, style, lighting, details
- Change: Framing/composition only
- Example: shallow depth of field → wide shot → bird's eye view
- Generate and save as "iteration-3-composition.png"

**For each iteration:**
1. Write the new prompt (mark what changed)
2. Generate the image
3. Compare to baseline
4. Note: Did this change have HIGH, MEDIUM, or LOW impact on the result?


---

## Step 3: Creative Challenge - Two Polished Images

Apply everything you've learned to create two polished, final images.

**Image 1: Travel Memory Card**

Design an image representing a meaningful moment or place from your research trip (or a place you dream of visiting).

**Your process:**
1. Start with the prompt structure formula
2. Write an initial prompt
3. Generate and evaluate
4. Refine 2-3 times based on what you learned from iterations
5. Save your final image and final prompt

**Image 2: Learning Journey Visualization**

Design an image representing your AI learning journey so far.

**Ideas:**
- Visual metaphor (e.g., "path through a forest of data")
- Workspace scene (your tools, voice workflows, NotebookLM glowing on screen)
- Abstract concept (AI and human collaboration, networks of knowledge)
- Before/after comparison (learning without AI vs with AI)

**Your process:**
1. Use a different subject/style than Image 1
2. Apply Description principles (be specific!)
3. Iterate 2-3 times

---

## Step 4: Complex Text Prompting - The 6-Component Framework

Description isn't just for images. Complex text tasks (like learning something new, creating plans, or analyzing information) also require clear, structured prompts.

**When you ask AI to teach you something complex**, vague prompts give vague results:
- ❌ "Tell me about Bridge" → AI guesses what you want, gives generic overview
- ✅ "Create a beginner-friendly Bridge learning guide with 6 sections..." → AI knows exactly what to deliver

**The 6-Component Framework for Excellent Complex Prompts:**

---

### 1. ROLE ASSIGNMENT

**What it is:** Tell the AI what expert persona to adopt

**Why it matters:** Changes the tone, depth, and approach of the response

**Examples:**
- "You are an expert teacher" → patient, clear explanations with examples
- "You are a researcher" → analytical, cited, evidence-focused
- "You are a coach" → motivational, action-oriented

---

### 2. CONTEXT & AUDIENCE

**What it is:** Your situation, knowledge level, goals, and constraints

**Why it matters:** AI calibrates complexity and doesn't make wrong assumptions

**Examples:**
- "I'm a complete beginner" → avoids jargon, explains basics
- "I'm traveling through Europe with mobile-only access" → considers constraints
- "I have 30 minutes to learn this" → focuses on essentials

---

### 3. TASK STATEMENT

**What it is:** Clear, specific deliverable you want

**Why it matters:** Prevents generic, unfocused responses

**Examples:**
- ❌ "Tell me about Bridge" → vague
- ✅ "Create a learning guide for Bridge" → specific deliverable

---

### 4. STRUCTURED REQUIREMENTS

**What it is:** Breaking the task into specific sections or components

**Why it matters:** Ensures comprehensive coverage; YOU control the scope, not the AI

**Examples:**
- "Include these 6 sections: Basics, Rules, Strategy, Common Mistakes, Quick Reference"
- "Cover 3 aspects: Setup, Gameplay, Scoring"
- Each section can have sub-requirements

---

### 5. CONSTRAINTS & TONE

**What it is:** Language level, style, what to include/avoid

**Why it matters:** Controls accessibility and voice

**Examples:**
- "Use simple language, explain jargon"
- "Keep it conversational and encouraging"
- "Include specific examples for each concept"

---

### 6. FORMAT SPECIFICATIONS

**What it is:** How the output should be structured for usability

**Why it matters:** Ensures you can actually USE the output (especially on mobile)

**Examples:**
- "Format with clear headings and bullets"
- "Create a 1-page reference card at the end"
- "Optimize for mobile reading (short paragraphs, scannable)"

---

**Add the Framework to NotebookLM:**

1. Create a new source: "6 Components Framework for Complex Prompts"

2. Copy this framework (all 6 components above)

3. Ask NotebookLM:
   - "How does this 6-component framework relate to the Description lesson from Anthropic AI Fluency?"
   - "Generate a Study Guide to test my understanding of these components"

4. Answer at least 3 Study Guide questions

**Why this matters:**
Just like image prompts need structure (Subject + Style + Composition...), complex text prompts need structure (Role + Context + Task...). Description is the common thread - being specific and structured produces better results every time.

---

## Step 5: Practice Complex Prompting - Learn a Card Game

**The Challenge:**

Use the 6-component framework to create an excellent prompt that teaches you a complex card game you've never played before.

**Part A: Choose Your Card Game**

Pick ONE card game you don't know well:
- **Bridge** (partnership trick-taking game, complex bidding)
- **Rummy** (set collection, sequencing)
- **Hearts** (trick-taking, avoid certain cards)
- **Spades** (partnership trick-taking)
- **Cribbage** (pegging, counting combinations)
- **Euchre** (trump-based trick-taking)

**Part B: Build Your Structured Prompt**

Use this template, filling in each component:

```
[1. ROLE ASSIGNMENT]
You are an expert [GAME] instructor who specializes in teaching absolute beginners.

[2. CONTEXT & AUDIENCE]
I've never played [GAME] before [add any relevant context: "but I want to learn to play with friends" or "and I'm traveling so need a self-contained mobile guide"].

[3. TASK STATEMENT]
Create a comprehensive [GAME] learning guide with these sections:

[4. STRUCTURED REQUIREMENTS]

1. BASICS
   - Number of players, deck, objective
   - Key terminology (define all game-specific terms)
   - Setup and dealing

2. RULES BREAKDOWN (step-by-step)
   - [Phase 1 of game - e.g., "Bidding phase" or "Drawing phase"]
   - [Phase 2 of game - e.g., "Playing phase" or "Melding phase"]
   - Scoring system (simplified for beginners)

3. BASIC STRATEGY
   - 3 beginner tips for [key aspect 1]
   - 3 beginner tips for [key aspect 2]
   - Common mistakes to avoid

4. PRACTICE SCENARIO
   - Walk through 1 example hand/round step-by-step
   - Show what a beginner should do and why

5. QUICK REFERENCE CARD
   - Format as a 1-page cheat sheet I can save on my phone
   - Include scoring, key terms, strategy reminders

[5. CONSTRAINTS & TONE]
Use simple language, avoid jargon without explaining it, include examples where helpful, and keep it encouraging for a complete beginner.

[6. FORMAT SPECIFICATIONS]
Format with clear headings and bullets for mobile reading. Keep paragraphs short and scannable.
```

**Part C: Test Your Prompt**

1. Copy your complete prompt
2. Paste it into ChatGPT, Claude, or Gemini
3. Review the output:
   - Did it cover all 5 sections you requested?
   - Is the language level appropriate for a beginner?
   - Is the Quick Reference Card actually useful?
   - Can you understand the game from this guide?

**Part D: Document in NotebookLM**

Create a new source: "Module 3 - Card Game Learning Guide - [Your Game]"

```markdown
## Card Game Learning Exercise

### Game Chosen
[Name of game]

### My Structured Prompt (6 Components)
[Paste your complete prompt - formatted to show the 6 components clearly]

### Output Received
[Paste the AI-generated learning guide]

### Evaluation Against Framework

**Component 1 (Role):** Did the AI adopt the expert teacher persona?
[Yes/No + evidence]

**Component 2 (Context):** Did the AI tailor content for a complete beginner?
[Yes/No + evidence]

**Component 3 (Task):** Did I get a learning guide (not just explanation)?
[Yes/No + evidence]

**Component 4 (Structure):** Did the output include all 5 requested sections?
[Yes/No + which sections were included/missing]

**Component 5 (Constraints):** Was the language simple and examples included?
[Yes/No + evidence]

**Component 6 (Format):** Is it mobile-friendly and scannable?
[Yes/No + evidence]

### What Worked
[2-3 things that worked well about this prompt]

### What I'd Improve
[2-3 things I'd change if I ran this prompt again]

### Connection to Description Principles
[How does this exercise demonstrate the Description D from the 4D Framework?]
```

**Ask NotebookLM to Evaluate Your Work:**

- "Evaluate my card game prompt against the 6-component framework - what's missing or weak?"
- "Based on the Description lesson principles, how could I make my prompt even more specific?"
- "What's the difference between my image prompts (structure formula) and my text prompts (6 components) - what's the common thread?"

**The Meta-Prompting Teaser:**

You just practiced **meta-prompting** - using AI to help you structure better prompts. There's a whole skill here (prompts that create prompts, prompts that evaluate prompts), but we're saving that for future modules. For now, notice: **Description is foundational to everything else**. You can't meta-prompt effectively if you can't describe what you want.

---

## Reflection & Portfolio

**Part A: Voice Reflection on Description**

Record a 2-3 minute voice note (using Voice Memos or Otter) reflecting on:
- What surprised you most about Description as a skill?
- How did image generation teach you to be more specific?
- What's the connection between image prompt structure and the 6-component framework?
- How will you use Description principles in future AI tasks?
- Which was harder - describing visual ideas or describing complex tasks? Why?

Save recording and add to NotebookLM:
- Title: "Module 3 - Description Reflection"

**Part B: Generate an Audio Overview**

Now you have 6+ sources in NotebookLM for this module:
1. AI Fluency - Description (4 sections)
2. Image tool guide
3. Image Prompt Structure Formula
4. Image Generation Experiments
5. 6 Components Framework
6. Card Game Learning Guide
7. Description Reflection

**Click "Audio Overview"** in NotebookLM and let it generate a 2-person AI podcast about YOUR Description journey. Listen to it and note:
- What did the AI hosts highlight as most important?
- Did they make connections you hadn't noticed?
- Is there anything they misunderstood (if so, what does that tell you about your documentation)?

**Part C: 4D Integration Reflection**

Write a short note (in NotebookLM or separate doc) connecting Description to the other Ds:

```markdown
## How Description Connects to the 4D Framework

**Delegation (1st D):**
[How does clear description help you delegate better to AI? Example: describing exactly what you want helps you know if AI is the right tool]

**Description (2nd D) - this module:**
[What's your biggest takeaway about Description as a skill?]

**Discernment (3rd D):**
[How does being specific help you evaluate AI outputs? Example: if your prompt was vague, how do you know if the output is good?]

**Diligence (4th D):**
[How does Description relate to responsible AI use? Example: clear prompts reduce hallucination risk]
```

Add this to NotebookLM as source: "Module 3 - 4D Integration Reflection"

---

## Definition of Done

### Image Generation:
- [ ] Image tool set up and tested
- [ ] Baseline image + 3 single-variable iterations completed
- [ ] 2 final creative images (Travel Memory + Learning Journey)
- [ ] All image experiments documented in NotebookLM


### Complex Text Prompting:
- [ ] Card game chosen and 6-component prompt created
- [ ] AI-generated learning guide received and evaluated
- [ ] Card game exercise documented in NotebookLM

### NotebookLM & Reflection:
- [ ] AI Fluency Description sections added (4 sources)
- [ ] Image tool guide added to NotebookLM
- [ ] Study Guides completed (Description + 6 Components)
- [ ] Voice reflection recorded and added
- [ ] Audio Overview generated and listened to
- [ ] 4D Integration reflection written

---

## Mobile Tips & Accessibility

**Image Generation on Mobile:**
- ChatGPT/DALL-E: Excellent iOS app, use voice to dictate long prompts
- Leonardo.Ai: iOS app available, mobile-friendly interface
- MidJourney: Discord app works on iPhone, use iOS dictation for prompts

**NotebookLM on Mobile:**
- The app can be buggy - use mobile browser with "Request Desktop Site" for easier uploads
- Voice recordings: Share directly to NotebookLM from Voice Memos app
- Give sources meaningful titles BEFORE uploading (the title becomes the source name)

**Complex Prompts on Mobile:**
- Draft long prompts in Voice Memos, then copy transcript to AI tool
- Build prompts incrementally (send role + context, then add requirements)
- Save working prompts in Notes app for reuse

**Low-Bandwidth Strategies:**
- Generate images at lower resolution first, refine only finals
- Download all images immediately (don't rely on history)
- Text prompts are lightweight - no bandwidth concerns

---

## Ethics & Responsible Use

**Image Rights & Ownership:**

- **ChatGPT/DALL-E**: You own images you create; check OpenAI terms for commercial use
- **Leonardo.Ai**: Review their ToS for ownership and licensing
- **MidJourney**: Paid subscribers get commercial rights; images are publicly visible

**Best Practices:**
- Document which tool and tier you used for each image
- Credit the AI tool when sharing publicly ("Created with DALL-E")
- Don't claim AI images as fully "your art" without disclosure
- Always verify current ToS before commercial use

**Ethical Prompting:**
- Avoid stereotypes in how you describe people, cultures, professions
- Be mindful of bias in your descriptions
- Don't include real people's names/faces without consent
- Keep locations general unless public landmarks

**Training Data:**
- DALL-E, Leonardo.Ai, and MidJourney are trained on internet images
- Ongoing debates about AI training and artist compensation
- Consider supporting human artists alongside using AI tools

**Card Game Learning:**
- Use AI guides as starting points, verify rules from official sources
- When teaching others, disclose you learned from AI (not years of experience)
- AI can make mistakes with complex game rules - cross-check if playing competitively

---

## What You Learned

**Description (2nd D) in action:**
- Clear, specific description is the foundation of all excellent prompts
- Vague language → vague results; Structured language → controlled results
- Description principles apply equally to images and complex text tasks

**Image Prompting:**
- Structure: Subject + Style + Composition + Lighting + Details
- Single-variable iteration reveals what each element controls
- Specificity determines your level of control over output

**Complex Text Prompting:**
- 6-Component Framework: Role, Context, Task, Structure, Constraints, Format
- Structured requirements let YOU control scope (AI doesn't guess)
- Meta-prompting builds on Description (you can't prompt about prompts without describing clearly)

**NotebookLM as Learning Partner:**
- Add both theory and practical docs to ground AI in YOUR context
- Ask questions, click citations, verify sources
- Study Guides and Audio Overviews reveal patterns you might miss
- Documentation + reflection = deeper learning

**Connection to Other 4Ds:**
- **Delegation**: Clear description helps you know if AI is the right tool
- **Discernment**: Specific prompts make it easier to evaluate if output matches intent
- **Diligence**: Structured prompts reduce hallucination and ethical risks

---

## Resources & Prompting Guides

**Image Generation:**
- [OpenAI - DALL-E Guide](https://platform.openai.com/docs/guides/images)
- [Leonardo.Ai - Help Center](https://help.leonardo.ai/)
- [MidJourney - Prompting Guide](https://docs.midjourney.com/docs/prompting)
- [MidJourney - Parameters Reference](https://docs.midjourney.com/docs/parameters)

**Text Prompting:**
- [Anthropic - Effective Prompting](https://docs.anthropic.com/claude/docs/effective-prompting)
- [Anthropic - Prompt Library](https://docs.anthropic.com/claude/prompt-library)
- [OpenAI - Text Generation Best Practices](https://platform.openai.com/docs/guides/text-generation)
- [Google - Gemini Prompting Best Practices](https://ai.google.dev/gemini-api/docs/prompting)

**AI Fluency:**
- [Anthropic AI Fluency Course](https://anthropic.skilljar.com/ai-fluency-framework-foundations)

---

**Ready for the next module?**

Now that you've mastered Description (being specific and structured), you're ready to practice **Discernment** (evaluating and verifying AI outputs with source-grounded research) or **Diligence** (handling long contexts and synthesis). Both build on the Description foundation you just created.
